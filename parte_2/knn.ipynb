{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcba4b8e-174e-4edc-a7f5-dca0db98d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from preprocessing import limpiar_datos, aplicar_dummy_variables_encoding, eliminar_features, entrenar_iterative_imputer, imputar_missings_iterative, reduccion_PCA, normalizar_dataframe, entrenar_normalizador_standard, entrenar_normalizador_minmax\n",
    "from graficos_modelos import mostrar_reporte_clasificacion, graficar_auc_roc,graficar_matriz_confusion\n",
    "from funciones_auxiliares import traer_datasets, traer_dataset_prediccion_final, separar_dataset, encontrar_hiperparametros_RGSCV, mapear_target_binario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f5146-35a4-4989-9d80-84c5b10061d3",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1bfe73-d902-4602-8a2e-b8497052a0ca",
   "metadata": {},
   "source": [
    "### Obtención de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052bae9-a800-47d4-b2f5-965497cdfa3e",
   "metadata": {},
   "source": [
    "Traemos datasets y particionamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3148b579-0c3a-41b8-b428-3366406e0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_sin_target, solo_target = traer_datasets()\n",
    "\n",
    "X_train, X_test, y_train, y_test = separar_dataset(df_sin_target, solo_target)\n",
    "\n",
    "X_train.is_copy=False\n",
    "X_test.is_copy=False\n",
    "y_train.is_copy=False\n",
    "y_test.is_copy=False\n",
    "\n",
    "y_train.set_index('id', inplace=True)\n",
    "y_train = y_train.sort_values(by=['id'], ascending=True).copy()\n",
    "\n",
    "y_test.set_index('id', inplace=True)\n",
    "y_test = y_test.sort_values(by=['id'], ascending=True).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caacc86-3f26-4f25-9b6e-d2d3ff3368e5",
   "metadata": {},
   "source": [
    "### Definiendo distintos preprocesamientos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96c41c9-18cb-4e31-b3a7-b5e9c0cf3bfc",
   "metadata": {},
   "source": [
    "Definiremos entonces dos preprocesamientos distintos a comparar para este modelo, y quedarnos con el mejor de ellos cuando probemos en holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d1536d8-12f0-4db2-8ef3-5e55ab9efea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesamiento_1(df_original:pd.DataFrame, imputer=None, normalizador=None):\n",
    "    df = df_original.copy(deep=True)\n",
    "    df = limpiar_datos(df)\n",
    "    df = aplicar_dummy_variables_encoding(df, ['llovieron_hamburguesas_hoy'])\n",
    "        \n",
    "    eliminar_features(df, df.columns.difference(['id', 'horas_de_sol', 'humedad_tarde', 'nubosidad_tarde', 'llovieron_hamburguesas_hoy_si', 'llovieron_hamburguesas_hoy_nan']))\n",
    "    \n",
    "    if(imputer is None):\n",
    "        imputer = entrenar_iterative_imputer(df)\n",
    "    df = imputar_missings_iterative(df, imputer)\n",
    "    \n",
    "    if(normalizador is None):\n",
    "        normalizador = entrenar_normalizador_standard(df)\n",
    "    df = normalizar_dataframe(df, normalizador)\n",
    "    \n",
    "    return df, imputer, normalizador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246dd8b5-9559-4153-9a0e-aa6d3889f844",
   "metadata": {},
   "source": [
    "Sabiendo que vamos a aplicar KNN, el cuál tiende a dejar de funcionar con dimensionalidad elevada, decidimos que el primer preprocesamiento realice una selección de features que se quede solamente con aquellas que determinamos como importantes en la primera parte del trabajo práctico. Adicionalmente además de realizar las conversiones e imputaciones necesarias, normalizaremos los datos con StandardScaler sabiendo que knn se beneficia de ello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7226754b-b3ba-417f-9f34-9b83e8a5f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesamiento_2(df_original:pd.DataFrame, imputer=None, normalizador=None):\n",
    "    df = df_original.copy(deep=True)\n",
    "    df = limpiar_datos(df)\n",
    "    df = aplicar_dummy_variables_encoding(df, ['llovieron_hamburguesas_hoy'])\n",
    "    eliminar_features(df, ['dia','barrio', 'direccion_viento_tarde', 'direccion_viento_temprano', 'rafaga_viento_max_direccion'])\n",
    "    \n",
    "    if(imputer is None):\n",
    "        imputer = entrenar_iterative_imputer(df)\n",
    "    df = imputar_missings_iterative(df, imputer)\n",
    "    \n",
    "    if(normalizador is None):\n",
    "        normalizador = entrenar_normalizador_minmax(df)\n",
    "    df= normalizar_dataframe(df, normalizador)\n",
    "    \n",
    "    df = reduccion_PCA(df, 5)\n",
    "    \n",
    "    return df, imputer, normalizador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8ac5c-a44c-457a-aed9-4e9d985e74ed",
   "metadata": {},
   "source": [
    "Para el segundo tipo de preprocesamiento, optaremos por eliminar menos features inicialmente (solo las categóricas que resultaron irrelevantes en la primera parte del TP), para al final del mismo aplicar una reducción de dimensionalidad con el algoritmo PCA. Adicionalmente, probaremos utilizando el normalizador MinMaxScaler en lugar de StandardScaler. Por lo demás, el preprocesamiento se mantiene similar al preprocesamiento 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac1f4c-05e8-4b72-99b7-d344e62a394e",
   "metadata": {},
   "source": [
    "### Aplicamos preprocesamientos 1 y 2 para obtener X_train_1 / X_test_1 y X_train_2 / X_test_2 respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02295686-aaae-4154-b253-c732c2eba9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, imputer_entrenado_1, normalizador_1 = preprocesamiento_1(X_train)\n",
    "X_test_1, imputer_entrenado_1, normalizador_1 = preprocesamiento_1(X_test, imputer_entrenado_1, normalizador_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28035e44-3558-461d-9e49-017ea0eb8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, imputer_entrenado_2, normalizador_2 = preprocesamiento_2(X_train)\n",
    "X_test_2, imputer_entrenado_2, normalizador_2 = preprocesamiento_2(X_test, imputer_entrenado_2, normalizador_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3626d4fb-27a9-4f93-b883-239502d88a7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Búsqueda de Hiperparámetros para el modelo que entrenará sobre X_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a8e07-17c6-40f3-8868-d95363332ddb",
   "metadata": {},
   "source": [
    "Buscamos hiperparámetros con RandomGridSearch, pues GridSearch iterativamente es bastante lento. Los parametros a optimizar en un modelo KNN son:\n",
    "- weights: (pesos) La funcion utilizada para asignarle el peso/importancia a cada punto.\n",
    "- n_neighbors: (vecinos) el número de vecinos que se observan antes de predecir la clase de una instancia nueva.\n",
    "- metric: La función utilizada para computar la distancia de los puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16bf2c9-0606-421d-9959-0e14bf33c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guillermo\\anaconda3\\envs\\orgadatos\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 12 is smaller than n_iter=100. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = {'weights': ['distance', 'uniform'], 'n_neighbors':[5, 10, 15],'metric': ['cosine','euclidean']}\n",
    "hiperparametros = encontrar_hiperparametros_RGSCV(KNeighborsClassifier(), params=params, x_np=X_train_1, y_np=y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10c8a2-9d3a-4ffd-a2f2-38d51a0ae6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "peso_elegido_1 = hiperparametros['weights']\n",
    "distancia_elegida_1 = hiperparametros['metric']\n",
    "k_vecinos_elegido_1 = hiperparametros['n_neighbors']\n",
    "print(f'Mejor peso: {peso_elegido_1}')\n",
    "print(f'Mejor tipo de distancia: {distancia_elegida_1}')\n",
    "print(f'Mejor cantidad de K vecinos: {k_vecinos_elegido_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5342653-7674-4ac6-990c-d79390cae5d6",
   "metadata": {},
   "source": [
    "### Entrenando el Modelo 1 sobre X_train_1 con CrossValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c86964-0d50-455b-acb9-8ea17a09a2c5",
   "metadata": {},
   "source": [
    "Procedemos a testear con kfolds, stratificados pues nuestro dataset es desbalanceado. Además, usamos los hiperparámetros encontrados previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2f2e1-9415-455d-a3ae-7476df162242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)\n",
    "for fold_idx, (train_index, test_index) in enumerate(kf.split(X_train_1, y_train)):\n",
    "    knn_clasificacion = KNeighborsClassifier(metric=distancia_elegida_1, n_neighbors=k_vecinos_elegido_1, weights=peso_elegido_1)\n",
    "    knn_clasificacion.fit(X_train_1[train_index], y_train.iloc[train_index].values.ravel())\n",
    "    print ('Reporte para el FOLD ' + str(fold_idx))\n",
    "    print(classification_report(y_train.iloc[test_index], knn_clasificacion.predict(X_train_1[test_index]), target_names=['No llueven hamburguesas al dia siguiente', 'Llueven hamburguesas al dia siguiente']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f70e4bd-ac0f-4564-9497-3b9fc2827b1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Búsqueda de Hiperparámetros para el modelo que entrenará sobre X_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c91977-605b-4bcd-9c6c-9d609178fa55",
   "metadata": {},
   "source": [
    "Buscamos hiperparámetros con RandomGridSearch, pues GridSearch iterativamente es bastante lento. Los parametros a optimizar en un modelo KNN son:\n",
    "- weights: (pesos) La funcion utilizada para asignarle el peso/importancia a cada punto.\n",
    "- n_neighbors: (vecinos) el número de vecinos que se observan antes de predecir la clase de una instancia nueva.\n",
    "- metric: La función utilizada para computar la distancia de los puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0c994-1dab-41ea-bea1-455a2ff025fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'weights': ['distance', 'uniform'], 'n_neighbors':[5, 10, 15],'metric': ['cosine','euclidean']}\n",
    "hiperparametros = encontrar_hiperparametros_RGSCV(KNeighborsClassifier(), params=params, x_np=X_train_2, y_np=y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e59e9-ece8-4e25-ae5b-8768a7c74273",
   "metadata": {},
   "outputs": [],
   "source": [
    "peso_elegido_2 = hiperparametros['weights']\n",
    "distancia_elegida_2 = hiperparametros['metric']\n",
    "k_vecinos_elegido_2 = hiperparametros['n_neighbors']\n",
    "print(f'Mejor peso: {peso_elegido_2}')\n",
    "print(f'Mejor tipo de distancia: {distancia_elegida_2}')\n",
    "print(f'Mejor cantidad de K vecinos: {k_vecinos_elegido_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a502e6-f7e5-4156-a790-e4d9f440ecfc",
   "metadata": {},
   "source": [
    "### Entrenando el Modelo 2 sobre X_train_2 con CrossValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b122e56-6a7b-44fd-a751-f25025f848a9",
   "metadata": {},
   "source": [
    "Procedemos a testear con kfolds, stratificados pues nuestro dataset es desbalanceado. Además, usamos los hiperparámetros encontrados previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4caa8-ae44-4950-ab49-cbace6b7bb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)\n",
    "for fold_idx, (train_index, test_index) in enumerate(kf.split(X_train_2, y_train)):\n",
    "    knn_clasificacion = KNeighborsClassifier(metric=distancia_elegida_2, n_neighbors=k_vecinos_elegido_2, weights=peso_elegido_2)\n",
    "    knn_clasificacion.fit(X_train_2[train_index], y_train.iloc[train_index].values.ravel())\n",
    "    print ('Reporte para el FOLD ' + str(fold_idx))\n",
    "    print(classification_report(y_train.iloc[test_index], knn_clasificacion.predict(X_train_2[test_index]), target_names=['No llueven hamburguesas al dia siguiente', 'Llueven hamburguesas al dia siguiente']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c18ef7c-6e61-469e-aaef-ed78e1e62286",
   "metadata": {},
   "source": [
    "### Predicción del modelo sobre holdout con el modelo que mejor resultó al hacer CrossValidation: Modelo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f16703-38ae-49fa-986c-1ddfecef41b8",
   "metadata": {},
   "source": [
    "Podemos ver al comparar ambos procesos de CrossValidation, que en general el modelo que usó el preprocesamiento_2 resultó en mejores métricas provistas por el classification report. En promedio, apreciamos un recall mejor, y en consecuencia también un f1 score mucho mejor para este modelo. Vemos además que no hay manifestaciones de overfit, por lo que pasaremos a utilizar el Modelo 2 para predecir sobre el dataset de holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe0a9f-961c-487d-8548-5e0bbafc7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_holdout = KNeighborsClassifier(metric=distancia_elegida_2, n_neighbors=k_vecinos_elegido_2, weights=peso_elegido_2)\n",
    "knn_holdout.fit(X_train_2, y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da92c3-cf58-431e-9592-f6df4337ae2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapeo_binario_v = np.vectorize(mapear_target_binario)\n",
    "y_pred = knn_holdout.predict(X_test_2)\n",
    "y_pred_binario = mapeo_binario_v(y_pred)\n",
    "y_pred_proba = knn_holdout.predict_proba(X_test_2)[:, 1]\n",
    "y_test_binario = y_test['llovieron_hamburguesas_al_dia_siguiente'].map({'si': 1, 'no': 0}).to_numpy()\n",
    "print(classification_report(y_test['llovieron_hamburguesas_al_dia_siguiente'].to_numpy(), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c1241-57e9-4aad-9fe5-7ec16424ccf7",
   "metadata": {},
   "source": [
    "### Curva AUC ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a29849-6959-4db6-ac1e-b34f9f3fd8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_auc_roc(y_test_binario, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8c853-f4cf-450d-a134-9881a86364d7",
   "metadata": {},
   "source": [
    "Se observa una métrica de auc roc bastante aceptable, en especial si la comparamos con nuestros resultados aplicando T-SNE antes de recibir correcciones al TP. Aún así, sigue siendo inferior a otros modelos presentados en este trabajo práctico, como por ejemplo el árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1f2cc-3d4a-4b92-9d39-ea3988da6627",
   "metadata": {},
   "source": [
    "# Matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e1bcf-6980-475f-bba0-73c6780b898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_matriz_confusion(y_test_binario, y_pred_binario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1892736e-5638-4f2e-83c1-5360fc34bc84",
   "metadata": {},
   "source": [
    "Podemos notar que si desprendemos los cálculos de Precision/Recall de la matriz resultante, estos coinciden con los reportados por classification_report(), y por lo tanto la confección de la misma es correcta. Si bien inicialmente vimos que el accuracy de KNN no fue malo, esta matriz nos indica claramente que para otras métricas el modelo no se comporta de manera satisfactoria, obteniendo solo un 0.43 de recall y 0.65 de precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a427a2-52ff-4141-ba6d-d08072191805",
   "metadata": {},
   "source": [
    "## Predicción con el dataset nuevo\n",
    "A continuación, realizamos la predicción con el modelo KNN sobre el dataset de predicciones nuevo, y la escribimos al archivo 'KNN.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01fc36b-d7fb-4052-94d3-3f2edca94f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from funciones_auxiliares import exportar_prediccion_final\n",
    "\n",
    "df_prediccion_final = traer_dataset_prediccion_final()\n",
    "ids = df_prediccion_final['id'].to_numpy()\n",
    "\n",
    "df_prediccion_final, imputer_entrenado_2, normalizador = preprocesamiento_2(df_prediccion_final, imputer_entrenado_2, normalizador_2)\n",
    "\n",
    "predicciones = knn_holdout.predict(df_prediccion_final)\n",
    "exportar_prediccion_final(ids, predicciones, 'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f7807-db91-4e3c-8663-5bdac111f528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
